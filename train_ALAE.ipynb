{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d549d0cb",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cba17b93-3040-4c0a-a5d2-37db49aeedec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as _it\n",
    "if not hasattr(_it, \"izip_longest\"):\n",
    "    _it.izip_longest = _it.zip_longest\n",
    "import tracker\n",
    "if not hasattr(tracker, \"RunningMeanTorch\"):\n",
    "    class RunningMeanTorch:\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            pass\n",
    "    tracker.RunningMeanTorch = RunningMeanTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37aa7bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sfh/ICNNFlow-new\n",
      "['toy_test-Copy5.ipynb', 'train_hdbm-Copy2.ipynb', 'train_hdbm-0623.ipynb', 'train_hdbm-Copy6.ipynb', '__pycache__', 'lib', '.ipynb_checkpoints', 'results', 'toy_test-Copy2.ipynb', 'ofm_transfer_mb128.png', 'test_ALAE.ipynb', '8gaussiantest.ipynb', 'src', 'toy_test-Copy3.ipynb', 'notebooks_utils.py', 'toy_test-Copy4.ipynb', 'c-reflow_benchmark.ipynb', 'backup', 'train_hdbm-idp.ipynb', 'toy_test.ipynb', '.gitignore', 'creflow_bm.ipynb', 'data', 'infer_icnn_flow.py', 'train_hdbm-Copy4.ipynb', 'train_hdbm-Copy1.ipynb', 'icnn_flow.py', 'reflow_benchmark-Copy1.ipynb', 'reflow_benchmark.ipynb', 'ALAE', 'W2_images.ipynb', 'train_ALAE.ipynb', 'ofmsrc', 'train_hdbm-Copy5.ipynb', 'toy_test-Copy1.ipynb', 'train_mnist.ipynb', 'ALAE_AC.ipynb', 'notebook', 'generators2d.py', 'datasets', 'benchmarks', 'train_hdbm.ipynb', 'reflow_benchmark-Copy2.ipynb', 'largetest.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../ALAE\")\n",
    "print(os.getcwd())\n",
    "print(os.listdir())\n",
    "import deeplake,zipfile,warnings\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ALAE.alae_ffhq_inference import load_model, encode, decode\n",
    "from notebooks_utils import TensorSampler\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import logging\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import copy\n",
    "import gc\n",
    "import time\n",
    "import ot as pot\n",
    "import ot\n",
    "from torch.serialization import safe_globals\n",
    "from ALAE.model     import Model          \n",
    "from ALAE.defaults  import get_cfg_defaults\n",
    "from ALAE.checkpointer import Checkpointer\n",
    "\n",
    "import torchvision.utils as vutils\n",
    "from torch import nn, autograd,Tensor\n",
    "from typing import Optional, Tuple, Dict\n",
    "from torch_fidelity import calculate_metrics\n",
    "from torch.distributions import Categorical, MultivariateNormal\n",
    "from torch.distributions.mixture_same_family import MixtureSameFamily\n",
    "from lib.act_func import Activations\n",
    "from lib.loss_func import compute_loss,compute_loss_back,compute_loss_meanflow_v1\n",
    "from lib.hjbflow import ICNN1,ICNN3,evaluation_straight,train_flow_mnist,evaluation_mnist,sample_ode_hj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea3e4ac5-8806-409b-a8aa-d6557bd34618",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"./results/FFHQ\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "logging.basicConfig(\n",
    "    filename=os.path.join(log_dir, \"train.log\"),\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s %(message)s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa38ee80",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55ca2628",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(0) \n",
    "\n",
    "input_data = 'MAN'\n",
    "target_data = 'WOMAN'\n",
    "\n",
    "# paras\n",
    "num_samples    = 100000  \n",
    "iterations     = 100000\n",
    "batch_size     = 1024\n",
    "lr             = 1e-2\n",
    "num_layers     = 10\n",
    "dim            = 512\n",
    "dimh           = 4096\n",
    "eps            = 1e-2\n",
    "act_fn         = Activations.get_act('celu')\n",
    "log_interval   = 5000\n",
    "loss_func=compute_loss_back\n",
    "\n",
    "logging.info(f\"hyperparams: samples={num_samples}, iters={iterations}, bs={batch_size}, lr={lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d207a09a",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38ee6df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ age.npy exist!\n",
      "✔ gender.npy exist!\n",
      "✔ latents.npy exist!\n",
      "✔ test_images.npy exist!\n"
     ]
    }
   ],
   "source": [
    "import gdown\n",
    "import os\n",
    "\n",
    "data_dir = 'data'\n",
    "if not os.path.isdir(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "urls = {\n",
    "    \"age.npy\": \"https://drive.google.com/uc?id=1Vi6NzxCsS23GBNq48E-97Z9UuIuNaxPJ\",\n",
    "    \"gender.npy\": \"https://drive.google.com/uc?id=1SEdsmQGL3mOok1CPTBEfc_O1750fGRtf\",\n",
    "    \"latents.npy\": \"https://drive.google.com/uc?id=1ENhiTRsHtSjIjoRu1xYprcpNd8M9aVu8\",\n",
    "    \"test_images.npy\": \"https://drive.google.com/uc?id=1SjBWWlPjq-dxX4kxzW-Zn3iUR3po8Z0i\",\n",
    "}\n",
    "for filename, url in urls.items():\n",
    "    file_path = os.path.join(data_dir, filename)\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"✔ {filename} exist!\")\n",
    "    else:\n",
    "        gdown.download(url, file_path, quiet=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f18d07a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "train_size = 60000\n",
    "test_size = 10000\n",
    "\n",
    "latents = np.load(\"data/latents.npy\")#70000*512\n",
    "gender = np.load(\"data/gender.npy\")#(70000, )\n",
    "age = np.load(\"data/age.npy\") #1\n",
    "test_inp_images = np.load(\"data/test_images.npy\") #300*1024*1024*3\n",
    "\n",
    "\n",
    "train_latents, test_latents = latents[:train_size], latents[train_size:]\n",
    "train_gender, test_gender = gender[:train_size], gender[train_size:]\n",
    "train_age, test_age = age[:train_size], age[train_size:]\n",
    "test_gender300 = gender[train_size : train_size + test_inp_images.shape[0]] \n",
    "if input_data == \"MAN\":\n",
    "    x_inds_train = np.arange(train_size)[(train_gender == \"male\").reshape(-1)]\n",
    "    x_inds_test = np.arange(test_size)[(test_gender == \"male\").reshape(-1)]\n",
    "elif input_data == \"WOMAN\":\n",
    "    x_inds_train = np.arange(train_size)[(train_gender == \"female\").reshape(-1)]\n",
    "    x_inds_test = np.arange(test_size)[(test_gender == \"female\").reshape(-1)]\n",
    "elif input_data == \"ADULT\":\n",
    "    x_inds_train = np.arange(train_size)[\n",
    "        (train_age >= 18).reshape(-1)*(train_age != -1).reshape(-1)\n",
    "    ]\n",
    "    x_inds_test = np.arange(test_size)[\n",
    "        (test_age >= 18).reshape(-1)*(test_age != -1).reshape(-1)\n",
    "    ]\n",
    "elif input_data == \"CHILDREN\":\n",
    "    x_inds_train = np.arange(train_size)[\n",
    "        (train_age < 18).reshape(-1)*(train_age != -1).reshape(-1)\n",
    "    ]\n",
    "    x_inds_test = np.arange(test_size)[\n",
    "        (test_age < 18).reshape(-1)*(test_age != -1).reshape(-1)\n",
    "    ]\n",
    "x_data_train = train_latents[x_inds_train]\n",
    "x_data_test = test_latents[x_inds_test]\n",
    "\n",
    "if target_data == \"MAN\":\n",
    "    y_inds_train = np.arange(train_size)[(train_gender == \"male\").reshape(-1)]\n",
    "    y_inds_test = np.arange(test_size)[(test_gender == \"male\").reshape(-1)]\n",
    "elif target_data == \"WOMAN\":\n",
    "    y_inds_train = np.arange(train_size)[(train_gender == \"female\").reshape(-1)]\n",
    "    y_inds_test = np.arange(test_size)[(test_gender == \"female\").reshape(-1)]\n",
    "elif target_data == \"ADULT\":\n",
    "    y_inds_train = np.arange(train_size)[\n",
    "        (train_age >= 18).reshape(-1)*(train_age != -1).reshape(-1)\n",
    "    ]\n",
    "    y_inds_test = np.arange(test_size)[\n",
    "        (test_age >= 18).reshape(-1)*(test_age != -1).reshape(-1)\n",
    "    ]\n",
    "elif target_data == \"CHILDREN\":\n",
    "    y_inds_train = np.arange(train_size)[\n",
    "        (train_age < 18).reshape(-1)*(train_age != -1).reshape(-1)\n",
    "    ]\n",
    "    y_inds_test = np.arange(test_size)[\n",
    "        (test_age < 18).reshape(-1)*(test_age != -1).reshape(-1)\n",
    "    ]\n",
    "y_data_train = train_latents[y_inds_train]\n",
    "y_data_test = test_latents[y_inds_test]\n",
    "\n",
    "X_train = torch.tensor(x_data_train)\n",
    "Y_train = torch.tensor(y_data_train)\n",
    "\n",
    "X_test = torch.tensor(x_data_test)\n",
    "Y_test = torch.tensor(y_data_test)\n",
    "\n",
    "X_sampler = TensorSampler(X_train, device=\"cpu\")\n",
    "Y_sampler = TensorSampler(Y_train, device=\"cpu\")\n",
    "# print(latents.shape)\n",
    "# print(gender.shape)\n",
    "print(test_gender300.shape)\n",
    "# print(age.shape)\n",
    "# print(test_inp_images.shape)\n",
    "# print(x_inds_test.shape)\n",
    "# print(y_inds_test.shape)\n",
    "\n",
    "\n",
    "from ALAE.discrete_ot import OTPlanSampler\n",
    "\n",
    "def get_discrete_ot_plan_sample_fn(sampler_x, sampler_y, device='cuda'):\n",
    "    ot_plan_sampler = OTPlanSampler('exact')\n",
    "    def ret_fn(batch_size):\n",
    "        x_samples = sampler_x.sample(batch_size).to(device)\n",
    "        y_samples = sampler_y.sample(batch_size).to(device)\n",
    "        return ot_plan_sampler.sample_plan(x_samples, y_samples)\n",
    "    return ret_fn\n",
    "\n",
    "sampling_fn = get_discrete_ot_plan_sample_fn(X_sampler, Y_sampler, device=device)\n",
    "X_sampler, Y_sampler = sampling_fn(batch_size)\n",
    "X_sampler = TensorSampler(X_sampler.detach().cpu(), device=device)\n",
    "Y_sampler = TensorSampler(Y_sampler.detach().cpu(), device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7dea1e",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40361673",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ICNN3(\n",
    "    dim=dim,\n",
    "    dim_t=1,\n",
    "    dimh=dimh,\n",
    "    num_hidden_layers=num_layers,\n",
    "    act_fn=act_fn,\n",
    "    batch_size=batch_size,\n",
    "    eps=eps\n",
    ").to(device)\n",
    "# model = ICNN1(\n",
    "#     dim=dim,\n",
    "#     dim_t=1,\n",
    "#     dimh=dimh,\n",
    "#     num_hidden_layers=num_layers,\n",
    "#     act_fn=act_fn,\n",
    "#     batch_size=batch_size,\n",
    "# ).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce81c8ee",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09faff54-fd21-4c1e-9acf-dd48154da8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def safe_torch_load(path, map_location=\"cpu\"):\n",
    "    if (not os.path.exists(path)) or (os.path.getsize(path) == 0) or (not zipfile.is_zipfile(path)):\n",
    "        warnings.warn(f\"[resume] invalid checkpoint: {path}; start fresh or fallback.\")\n",
    "        return None\n",
    "    try:\n",
    "        return torch.load(path, map_location=map_location, weights_only=True)\n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"[resume] failed to load {path}: {e}; start fresh or fallback.\")\n",
    "        return None\n",
    "\n",
    "def atomic_torch_save(obj, path):\n",
    "    tmp = path + \".tmp\"\n",
    "    with open(tmp, \"wb\") as f:\n",
    "        torch.save(obj, f)\n",
    "        f.flush(); os.fsync(f.fileno())  \n",
    "    os.replace(tmp, path)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056e4948",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3175719/3520829162.py:3: UserWarning: [resume] invalid checkpoint: ./results/FFHQ/1023nosp/checkpoint0915.pth; start fresh or fallback.\n",
      "  warnings.warn(f\"[resume] invalid checkpoint: {path}; start fresh or fallback.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training\n",
      "Training iter 0 to 4999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                      | 1/5000 [00:01<2:01:08,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0/5000 — total 0.5596, FM 0.5596, HJ 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                    | 61/5000 [01:23<1:54:36,  1.39s/it]"
     ]
    }
   ],
   "source": [
    "chunk = 5000\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "checkpoint_path = os.path.join(log_dir, \"checkpoint.pth\")\n",
    "checkpoint_prev = os.path.join(log_dir, \"checkpoint_prev.pth\")  # \n",
    "\n",
    "start_iter = 0\n",
    "loss_history = []\n",
    "\n",
    "ck = safe_torch_load(checkpoint_path, map_location=device)\n",
    "if ck is None and os.path.exists(checkpoint_prev):\n",
    "    ck = safe_torch_load(checkpoint_prev, map_location=device)\n",
    "\n",
    "if ck is not None:\n",
    "    model.load_state_dict(ck[\"model_state\"], strict=False)\n",
    "    optimizer.load_state_dict(ck[\"optimizer_state\"])\n",
    "    start_iter = ck.get(\"iteration\", 0) + 1\n",
    "    loss_history = ck.get(\"loss_history\", [])\n",
    "    print(f\"from iter {start_iter} continuing, loss_history:{len(loss_history)}\")\n",
    "else:\n",
    "    print(\"Begin training\")\n",
    "\n",
    "\n",
    "current_iter = start_iter\n",
    "try:\n",
    "    while current_iter < iterations:\n",
    "        this_chunk = min(chunk, iterations - current_iter)\n",
    "        print(f\"Training iter {current_iter} to {current_iter + this_chunk - 1}\")\n",
    "\n",
    "        loss_seg = train_flow_mnist(\n",
    "            model, optimizer,\n",
    "            X_sampler, Y_sampler,\n",
    "            iterations=this_chunk,\n",
    "            batch_size=batch_size,\n",
    "            loss_func=loss_func,\n",
    "            log_interval=log_interval,\n",
    "            benchmark=None,\n",
    "            minibatch=True,\n",
    "        )\n",
    "\n",
    "        loss_history.extend(loss_seg)\n",
    "        current_iter += this_chunk\n",
    "\n",
    "        payload = {\n",
    "            \"iteration\"      : current_iter - 1,\n",
    "            \"model_state\"    : model.state_dict(),\n",
    "            \"optimizer_state\": optimizer.state_dict(),\n",
    "            \"loss_history\"   : loss_history,\n",
    "            \"hyperparams\"    : {\n",
    "                \"num_hidden_layers\": num_layers,\n",
    "                \"dimh\"             : dimh,\n",
    "                \"activation\"       : act_fn.__name__,\n",
    "                \"batch_size\"       : batch_size,\n",
    "                \"lr\"               : lr,\n",
    "            },\n",
    "            \"model_name\": model.__class__.__name__,\n",
    "            \"model_structure\": str(model),\n",
    "        }\n",
    "\n",
    "        \n",
    "        if os.path.exists(checkpoint_path):\n",
    "            try:\n",
    "                os.replace(checkpoint_path, checkpoint_prev)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        atomic_torch_save(payload, checkpoint_path)\n",
    "        print(f\"save checkpoint to iter {current_iter - 1}\")\n",
    "\n",
    "    print(\"Finish Loading\")\n",
    "except KeyboardInterrupt:\n",
    "    payload = {\n",
    "        \"iteration\"      : current_iter - 1,\n",
    "        \"model_state\"    : model.state_dict(),\n",
    "        \"optimizer_state\": optimizer.state_dict(),\n",
    "        \"loss_history\"   : loss_history,\n",
    "    }\n",
    "    atomic_torch_save(payload, checkpoint_path)\n",
    "    print(f\"Interrupted, save checkpoint to iter {current_iter - 1}\")\n",
    "    raise\n",
    "\n",
    "train_time = time.time() - start_time\n",
    "logging.info(f\"Training completed in {train_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(loss_history)\n",
    "plt.title(\"Training Loss on FFHQ\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(log_dir, \"loss_FFHQ.png\"))\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
